{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e765b9a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:39:04.078277Z",
     "start_time": "2022-05-10T00:38:47.468716Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from collections import defaultdict\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from vecstack import stacking, StackingTransformer\n",
    "\n",
    "from sklearn.metrics import log_loss,accuracy_score\n",
    "\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6bff32",
   "metadata": {},
   "source": [
    "# pycaret으로 직업 예측 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ac813",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469d4300",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:39:18.037148Z",
     "start_time": "2022-05-10T00:39:17.869561Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_occpy_pred_final.csv')\n",
    "test = pd.read_csv('./data/test_occpy_pred_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9412e6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:39:18.700751Z",
     "start_time": "2022-05-10T00:39:18.646926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>credit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>-13899</td>\n",
       "      <td>-4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accountants</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-11380</td>\n",
       "      <td>-1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-19087</td>\n",
       "      <td>-4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-15088</td>\n",
       "      <td>-2092</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sales staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>-15037</td>\n",
       "      <td>-2105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender car reality  child_num  income_total  \\\n",
       "0           0      F   N       N          0      202500.0   \n",
       "1           1      F   N       Y          1      247500.0   \n",
       "2           2      M   Y       Y          0      450000.0   \n",
       "3           3      F   N       Y          0      202500.0   \n",
       "4           4      F   Y       Y          0      157500.0   \n",
       "\n",
       "            income_type                       edu_type     family_type  \\\n",
       "0  Commercial associate               Higher education         Married   \n",
       "1  Commercial associate  Secondary / secondary special  Civil marriage   \n",
       "2               Working               Higher education         Married   \n",
       "3  Commercial associate  Secondary / secondary special         Married   \n",
       "4         State servant               Higher education         Married   \n",
       "\n",
       "            house_type  DAYS_BIRTH  DAYS_EMPLOYED  work_phone  phone  email  \\\n",
       "0  Municipal apartment      -13899          -4709           0      0      0   \n",
       "1    House / apartment      -11380          -1540           0      0      1   \n",
       "2    House / apartment      -19087          -4434           0      1      0   \n",
       "3    House / apartment      -15088          -2092           0      1      0   \n",
       "4    House / apartment      -15037          -2105           0      0      0   \n",
       "\n",
       "    occyp_type  family_size  begin_month  credit  \n",
       "0  Accountants          2.0         -6.0     1.0  \n",
       "1     Laborers          3.0         -5.0     1.0  \n",
       "2     Managers          2.0        -22.0     2.0  \n",
       "3  Sales staff          2.0        -37.0     0.0  \n",
       "4     Managers          2.0        -26.0     2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5de98a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:39:28.148410Z",
     "start_time": "2022-05-10T00:39:28.082585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>credit</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>Municipal apartment</td>\n",
       "      <td>4709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Accountants</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>Commercial associate</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>1540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>4434</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Managers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender car reality  child_num  income_total           income_type  \\\n",
       "0      F   N       N          0      202500.0  Commercial associate   \n",
       "1      F   N       Y          1      247500.0  Commercial associate   \n",
       "2      M   Y       Y          0      450000.0               Working   \n",
       "\n",
       "                        edu_type     family_type           house_type  \\\n",
       "0               Higher education         Married  Municipal apartment   \n",
       "1  Secondary / secondary special  Civil marriage    House / apartment   \n",
       "2               Higher education         Married    House / apartment   \n",
       "\n",
       "   DAYS_EMPLOYED  work_phone  phone  email   occyp_type  family_size  \\\n",
       "0           4709           0      0      0  Accountants          2.0   \n",
       "1           1540           0      0      1     Laborers          3.0   \n",
       "2           4434           0      1      0     Managers          2.0   \n",
       "\n",
       "   begin_month  credit  age  \n",
       "0          6.0     1.0   38  \n",
       "1          5.0     1.0   31  \n",
       "2         22.0     2.0   52  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['age'] = train.DAYS_BIRTH.apply(lambda x : -x // 365)\n",
    "train.DAYS_EMPLOYED = (-1) * train.DAYS_EMPLOYED \n",
    "train.loc[(train.DAYS_EMPLOYED < 0), 'DAYS_EMPLOYED'] = 0\n",
    "train.begin_month = (-1) * train.begin_month\n",
    "# train['personal_id'] = train['gender'] + \"_\" + train['DAYS_BIRTH'].astype(str) + \"_\" + train['income_total'].astype(str) + \"_\" + train['income_type'].astype(str)\n",
    "# train.gender = train.gender.replace({'F' : 0, 'M' : 1})\n",
    "# train.car = train.car.replace({'N' : 0, 'Y' : 1})\n",
    "# train.reality = train.reality.replace({'N' : 0, 'Y' : 1})\n",
    "\n",
    "train = train.drop(['Unnamed: 0','DAYS_BIRTH'], axis = 1)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c63fe6a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:39:29.673349Z",
     "start_time": "2022-05-10T00:39:29.618419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>car</th>\n",
       "      <th>reality</th>\n",
       "      <th>child_num</th>\n",
       "      <th>income_total</th>\n",
       "      <th>income_type</th>\n",
       "      <th>edu_type</th>\n",
       "      <th>family_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>DAYS_EMPLOYED</th>\n",
       "      <th>work_phone</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>occyp_type</th>\n",
       "      <th>family_size</th>\n",
       "      <th>begin_month</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Pensioner</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Civil marriage</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Security staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>State servant</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>8671</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>69372.0</td>\n",
       "      <td>Working</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>Married</td>\n",
       "      <td>House / apartment</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender car reality  child_num  income_total    income_type  \\\n",
       "0      M   Y       N          0      112500.0      Pensioner   \n",
       "1      F   N       Y          0      135000.0  State servant   \n",
       "2      F   N       Y          0       69372.0        Working   \n",
       "\n",
       "                        edu_type     family_type         house_type  \\\n",
       "0  Secondary / secondary special  Civil marriage  House / apartment   \n",
       "1               Higher education         Married  House / apartment   \n",
       "2  Secondary / secondary special         Married  House / apartment   \n",
       "\n",
       "   DAYS_EMPLOYED  work_phone  phone  email      occyp_type  family_size  \\\n",
       "0              0           0      1      0  Security staff          2.0   \n",
       "1           8671           0      1      0      Core staff          2.0   \n",
       "2            217           1      1      0        Laborers          2.0   \n",
       "\n",
       "   begin_month  age  \n",
       "0         60.0   60  \n",
       "1         36.0   51  \n",
       "2         40.0   43  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['age'] = test.DAYS_BIRTH.apply(lambda x : -x // 365)\n",
    "test.DAYS_EMPLOYED = (-1) * test.DAYS_EMPLOYED \n",
    "test.loc[(test.DAYS_EMPLOYED < 0), 'DAYS_EMPLOYED'] = 0\n",
    "test.begin_month = (-1) * test.begin_month\n",
    "# test['personal_id'] = test['gender'] + \"_\" + test['DAYS_BIRTH'].astype(str) + \"_\" + test['income_total'].astype(str) + \"_\" + test['income_type'].astype(str)\n",
    "# test.gender = test.gender.replace({'F' : 0, 'M' : 1})\n",
    "# test.car = test.car.replace({'N' : 0, 'Y' : 1})\n",
    "# test.reality = test.reality.replace({'N' : 0, 'Y' : 1})\n",
    "\n",
    "test = test.drop(['Unnamed: 0','DAYS_BIRTH'], axis = 1)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c80b60f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:39:37.982957Z",
     "start_time": "2022-05-10T00:39:37.967746Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train.credit\n",
    "X = train.drop(['credit'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72803a94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:39:38.481480Z",
     "start_time": "2022-05-10T00:39:38.457540Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3657a5",
   "metadata": {},
   "source": [
    "## scaled_X_train, y_train 으로 학습\n",
    "## scaled_X_test, y_test 로 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b46b432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:40:09.788863Z",
     "start_time": "2022-05-10T00:40:09.772906Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be017ae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:40:11.932356Z",
     "start_time": "2022-05-10T00:40:11.822645Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['child_num', 'income_total', 'DAYS_EMPLOYED', 'family_size', 'begin_month', 'age']\n",
    "categorical_features = ['gender','car','reality','income_type','edu_type','family_type','house_type','work_phone','phone','email','occyp_type']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "numeric_transformer.fit(X_train[numeric_features])\n",
    "X_train[numeric_features] = numeric_transformer.transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = numeric_transformer.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e6f0ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:43:08.110946Z",
     "start_time": "2022-05-10T00:41:09.712430Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.765699950649888"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_catboost = CatBoostClassifier(iterations=500, random_state=123, early_stopping_rounds=50)\n",
    "clf_catboost.fit(X_train, y_train, \n",
    "                 cat_features=categorical_features, verbose=0)\n",
    "\n",
    "pred_proba = clf_catboost.predict_proba(X_test)\n",
    "log_loss(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33ad3ea",
   "metadata": {},
   "source": [
    "### 전체 데이터로 학습 -> 데이콘 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece9ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65530560",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:48:01.244484Z",
     "start_time": "2022-05-10T00:48:01.229397Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_y = train.credit\n",
    "train_X = train.drop('credit', axis = 1)\n",
    "test_X = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d236cba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:48:11.518277Z",
     "start_time": "2022-05-10T00:48:11.430291Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['child_num', 'income_total', 'DAYS_EMPLOYED', 'family_size', 'begin_month', 'age']\n",
    "categorical_features = ['gender','car','reality','income_type','edu_type','family_type','house_type','work_phone','phone','email','occyp_type']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "numeric_transformer.fit(X_train[numeric_features])\n",
    "train_X[numeric_features] = numeric_transformer.transform(train_X[numeric_features])\n",
    "test_X[numeric_features] = numeric_transformer.transform(test_X[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "922beddb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T00:51:40.060581Z",
     "start_time": "2022-05-10T00:48:54.781344Z"
    }
   },
   "outputs": [],
   "source": [
    "clf_catboost = CatBoostClassifier(iterations=500, random_state=123, early_stopping_rounds=50)\n",
    "clf_catboost.fit(train_X, train_y, \n",
    "                 cat_features=categorical_features, verbose=0)\n",
    "\n",
    "pred_proba = clf_catboost.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76fc225",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T01:02:03.224779Z",
     "start_time": "2022-05-10T01:02:03.154395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>0.119836</td>\n",
       "      <td>0.841252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.138120</td>\n",
       "      <td>0.130527</td>\n",
       "      <td>0.731353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.087454</td>\n",
       "      <td>0.083996</td>\n",
       "      <td>0.828550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.185575</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.710411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.136003</td>\n",
       "      <td>0.201789</td>\n",
       "      <td>0.662209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>0.144568</td>\n",
       "      <td>0.227455</td>\n",
       "      <td>0.627978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>0.095697</td>\n",
       "      <td>0.307315</td>\n",
       "      <td>0.596989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>0.067375</td>\n",
       "      <td>0.895560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>0.072639</td>\n",
       "      <td>0.156135</td>\n",
       "      <td>0.771226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>0.049623</td>\n",
       "      <td>0.151679</td>\n",
       "      <td>0.798698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         0         1         2\n",
       "0     26457  0.038912  0.119836  0.841252\n",
       "1     26458  0.138120  0.130527  0.731353\n",
       "2     26459  0.087454  0.083996  0.828550\n",
       "3     26460  0.185575  0.104015  0.710411\n",
       "4     26461  0.136003  0.201789  0.662209\n",
       "...     ...       ...       ...       ...\n",
       "9995  36452  0.144568  0.227455  0.627978\n",
       "9996  36453  0.095697  0.307315  0.596989\n",
       "9997  36454  0.037065  0.067375  0.895560\n",
       "9998  36455  0.072639  0.156135  0.771226\n",
       "9999  36456  0.049623  0.151679  0.798698\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.loc[:, 1:] = pred_proba\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdbd0605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T01:02:20.985545Z",
     "start_time": "2022-05-10T01:02:20.873974Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./data/submission_CATBOOST.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85423e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e511c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19f4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5847a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c49e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9218dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b280417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd1070a4",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6f97db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T00:35:28.781225Z",
     "start_time": "2022-05-09T00:35:28.763275Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "               colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
    "               early_stopping_rounds=None, enable_categorical=False,\n",
    "               eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
    "               importance_type=None, interaction_constraints='',\n",
    "               learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,\n",
    "               max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,\n",
    "               missing=np.nan, monotone_constraints='()', n_estimators=170,\n",
    "               n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',\n",
    "               predictor='auto', random_state=42, reg_alpha=10)\n",
    "\n",
    "lgbm_clf = LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',\n",
    "                class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,\n",
    "                importance_type='split', learning_rate=0.2, max_depth=-1,\n",
    "                min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,\n",
    "                n_estimators=100, n_jobs=-1, num_leaves=30, objective=None,\n",
    "                random_state=42, reg_alpha=0.001, reg_lambda=5, silent='warn',\n",
    "                subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                            learning_rate=0.1, loss='deviance', max_depth=8,\n",
    "                            max_features='sqrt', max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.001, min_impurity_split=None,\n",
    "                            min_samples_leaf=5, min_samples_split=10,\n",
    "                            min_weight_fraction_leaf=0.0, n_estimators=290,\n",
    "                            n_iter_no_change=None, \n",
    "                            random_state=42, subsample=0.25, tol=0.0001,\n",
    "                            validation_fraction=0.1, verbose=0,\n",
    "                            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1234188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T00:40:55.199997Z",
     "start_time": "2022-05-09T00:36:45.821935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [XGBClassifier]\n",
      "[09:36:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:36:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:37:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:37:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:37:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:37:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:38:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:38:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    ----\n",
      "    MEAN:     [0.69964564] + [0.00527104]\n",
      "    FULL:     [0.69964564]\n",
      "\n",
      "model  1:     [LGBMClassifier]\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "    ----\n",
      "    MEAN:     [0.69818096] + [0.00324121]\n",
      "    FULL:     [0.69818096]\n",
      "\n",
      "model  2:     [GradientBoostingClassifier]\n",
      "    ----\n",
      "    MEAN:     [0.68684148] + [0.00450864]\n",
      "    FULL:     [0.68684148]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [xgb_clf, lgbm_clf, gb_clf]\n",
    "\n",
    "S_train, S_test = stacking(models, \n",
    "                       scaled_X_train, y_train, scaled_X_test, \n",
    "                       regression = False, \n",
    "                       metric = accuracy_score,\n",
    "#                        needs_proba = True,                           \n",
    "                       n_folds = 5, stratified = True, shuffle = True, \n",
    "                       random_state = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a76a8e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T00:40:55.700265Z",
     "start_time": "2022-05-09T00:40:55.689293Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_final = XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "               colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
    "               early_stopping_rounds=None, enable_categorical=False,\n",
    "               eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
    "               importance_type=None, interaction_constraints='',\n",
    "               learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,\n",
    "               max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,\n",
    "               missing=np.nan, monotone_constraints='()', n_estimators=170,\n",
    "               n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',\n",
    "               predictor='auto', random_state=42, reg_alpha=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4629afc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T00:40:58.664867Z",
     "start_time": "2022-05-09T00:40:56.033277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:40:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_final.fit(S_train, y_train)\n",
    "pred_proba = xgb_final.predict_proba(S_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c428461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T00:40:59.253602Z",
     "start_time": "2022-05-09T00:40:59.211714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7116402116402116\n"
     ]
    }
   ],
   "source": [
    "pred = xgb_final.predict(S_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "950b8b25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T00:40:59.705472Z",
     "start_time": "2022-05-09T00:40:59.678531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792928575207947"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d1273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf54f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7184c0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:13:17.082339Z",
     "start_time": "2022-05-08T06:13:17.066382Z"
    }
   },
   "outputs": [],
   "source": [
    "train_y = train.credit\n",
    "train_X = train.drop('credit', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "163b417a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:13:17.448765Z",
     "start_time": "2022-05-08T06:13:17.440748Z"
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['child_num', 'income_total', 'DAYS_EMPLOYED', 'family_size', 'begin_month', 'age']\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_features = ['income_type', 'edu_type', 'family_type', 'house_type','occyp_type']\n",
    "categorical_transformer = OneHotEncoder(categories='auto', handle_unknown = 'ignore')\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', numeric_transformer, numeric_features),\n",
    "                    ('cat', categorical_transformer, categorical_features)\n",
    "                ], remainder='passthrough'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fef57e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:13:21.362745Z",
     "start_time": "2022-05-08T06:13:21.244281Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor.fit(train_X)\n",
    "scaled_train = preprocessor.transform(train_X)\n",
    "scaled_test = preprocessor.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4da7cfcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:13:23.360227Z",
     "start_time": "2022-05-08T06:13:23.344234Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "               colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7,\n",
    "               early_stopping_rounds=None, enable_categorical=False,\n",
    "               eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
    "               importance_type=None, interaction_constraints='',\n",
    "               learning_rate=0.3, max_bin=256, max_cat_to_onehot=4,\n",
    "               max_delta_step=0, max_depth=8, max_leaves=0, min_child_weight=2,\n",
    "               missing=np.nan, monotone_constraints='()', n_estimators=170,\n",
    "               n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',\n",
    "               predictor='auto', random_state=42, reg_alpha=10)\n",
    "\n",
    "lgbm_clf = LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',\n",
    "                class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,\n",
    "                importance_type='split', learning_rate=0.2, max_depth=-1,\n",
    "                min_child_samples=6, min_child_weight=0.001, min_split_gain=0.6,\n",
    "                n_estimators=100, n_jobs=-1, num_leaves=30, objective=None,\n",
    "                random_state=42, reg_alpha=0.001, reg_lambda=5, silent='warn',\n",
    "                subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                            learning_rate=0.1, loss='deviance', max_depth=8,\n",
    "                            max_features='sqrt', max_leaf_nodes=None,\n",
    "                            min_impurity_decrease=0.001, min_impurity_split=None,\n",
    "                            min_samples_leaf=5, min_samples_split=10,\n",
    "                            min_weight_fraction_leaf=0.0, n_estimators=290,\n",
    "                            n_iter_no_change=None, \n",
    "                            random_state=42, subsample=0.25, tol=0.0001,\n",
    "                            validation_fraction=0.1, verbose=0,\n",
    "                            warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd6fb1da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:29:51.075838Z",
     "start_time": "2022-05-08T06:29:51.065865Z"
    }
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('XGB', xgb_clf),\n",
    "    ('LGBM', lgbm_clf),\n",
    "    ('GB', gb_clf)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa81251b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:29:51.652533Z",
     "start_time": "2022-05-08T06:29:51.637090Z"
    }
   },
   "outputs": [],
   "source": [
    "stack = StackingTransformer(estimators,\n",
    "                       regression = False, \n",
    "                       metric = accuracy_score,\n",
    "#                        needs_proba = True,                           \n",
    "                       n_folds = 5, stratified = True, shuffle = True, \n",
    "                       random_state = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc0b5909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:31:41.404811Z",
     "start_time": "2022-05-08T06:29:53.109340Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "variant:      [A]\n",
      "n_estimators: [3]\n",
      "\n",
      "estimator  0: [XGB: XGBClassifier]\n",
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:30:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"max_cat_to_onehot\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:30:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "    MEAN:     [0.70586246] + [0.00285516]\n",
      "\n",
      "estimator  1: [LGBM: LGBMClassifier]\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "    MEAN:     [0.69773614] + [0.00339640]\n",
      "\n",
      "estimator  2: [GB: GradientBoostingClassifier]\n",
      "    MEAN:     [0.70578680] + [0.00477084]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingTransformer(estimators=[('XGB',\n",
       "                                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                               callbacks=None,\n",
       "                                               colsample_bylevel=1,\n",
       "                                               colsample_bynode=1,\n",
       "                                               colsample_bytree=0.7,\n",
       "                                               early_stopping_rounds=None,\n",
       "                                               enable_categorical=False,\n",
       "                                               eval_metric=None, gamma=0,\n",
       "                                               gpu_id=-1,\n",
       "                                               grow_policy='depthwise',\n",
       "                                               importance_type=None,\n",
       "                                               interaction_constraints='',\n",
       "                                               learning_rate=0.3, max_bin=256,\n",
       "                                               m...\n",
       "                                                num_leaves=30, random_state=42,\n",
       "                                                reg_alpha=0.001,\n",
       "                                                reg_lambda=5)),\n",
       "                                ('GB',\n",
       "                                 GradientBoostingClassifier(max_depth=8,\n",
       "                                                            max_features='sqrt',\n",
       "                                                            min_impurity_decrease=0.001,\n",
       "                                                            min_samples_leaf=5,\n",
       "                                                            min_samples_split=10,\n",
       "                                                            n_estimators=290,\n",
       "                                                            random_state=42,\n",
       "                                                            subsample=0.25))],\n",
       "                    metric=<function accuracy_score at 0x00000237BA2205E0>,\n",
       "                    n_folds=5, regression=False, shuffle=True, stratified=True,\n",
       "                    verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack.fit(scaled_train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24427ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:39:00.793904Z",
     "start_time": "2022-05-08T06:38:56.335754Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [XGB: XGBClassifier]\n",
      "    DONE\n",
      "\n",
      "estimator  1: [LGBM: LGBMClassifier]\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: GradientBoostingClassifier]\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [XGB: XGBClassifier]\n",
      "    DONE\n",
      "\n",
      "estimator  1: [LGBM: LGBMClassifier]\n",
      "    DONE\n",
      "\n",
      "estimator  2: [GB: GradientBoostingClassifier]\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train = stack.transform(scaled_train)\n",
    "S_test = stack.transform(scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f00dfc7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:39:28.893846Z",
     "start_time": "2022-05-08T06:39:28.072560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(seed = 0, n_jobs = -1, learning_rate = 0.1, n_estimators = 100, max_depth = 3, eval_metric='mlogloss') \n",
    "model = model.fit(S_train, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f19e299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:39:41.630478Z",
     "start_time": "2022-05-08T06:39:41.608538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. ... 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(S_test) \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9c7141c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:40:51.491899Z",
     "start_time": "2022-05-08T06:40:51.450002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10300916 0.17039236 0.72659844]\n",
      " [0.10300916 0.17039236 0.72659844]\n",
      " [0.10300916 0.17039236 0.72659844]\n",
      " ...\n",
      " [0.10300916 0.17039236 0.72659844]\n",
      " [0.10300916 0.17039236 0.72659844]\n",
      " [0.10300916 0.17039236 0.72659844]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict_proba(S_test) \n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e38062d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:49:08.902768Z",
     "start_time": "2022-05-08T06:49:08.875800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-1d42f7cf5abb>:2: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  submission.loc[:, 1:] = y_pred_proba\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26457</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26458</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26459</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26460</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26461</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>36452</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>36453</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>36454</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>36455</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36456</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.726598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         0         1         2\n",
       "0     26457  0.103009  0.170392  0.726598\n",
       "1     26458  0.103009  0.170392  0.726598\n",
       "2     26459  0.103009  0.170392  0.726598\n",
       "3     26460  0.103009  0.170392  0.726598\n",
       "4     26461  0.103009  0.170392  0.726598\n",
       "...     ...       ...       ...       ...\n",
       "9995  36452  0.103009  0.170392  0.726598\n",
       "9996  36453  0.103009  0.170392  0.726598\n",
       "9997  36454  0.103009  0.170392  0.726598\n",
       "9998  36455  0.103009  0.170392  0.726598\n",
       "9999  36456  0.103009  0.170392  0.726598\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission.loc[:, 1:] = y_pred_proba\n",
    "submission\n",
    "submission.to_csv('./data/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d303c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:49:21.902832Z",
     "start_time": "2022-05-08T06:49:21.827421Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('./data/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa1080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514115f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9cc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ef7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da970d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f101b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
