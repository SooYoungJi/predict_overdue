{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Keras_tuner_for_Bayesian_HPO_0429ver.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTuOBLppfF9s"
      },
      "source": [
        "### * \\[important] This notebook is **only for Colab-execution**, please use colaboratory to test following codes.\n",
        "### * \\[important] Change runtime type to GPU first & execute following cells\n",
        "### * Official Github repository & documents @ https://github.com/keras-team/keras-tuner\n",
        "### * Keras-tuner Basic tutorial (TF official document) @ https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCn9n7sKfeZQ"
      },
      "source": [
        "<br>\n",
        "\n",
        "## 1. Install Keras-Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "528U3VTVScOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67961d0c-4bf6-485f-ec2e-7a581e50bdc0"
      },
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 20 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 40 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133 kB 4.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EZvxEozygAh"
      },
      "source": [
        "* Following codes are tested under **Tensorflow==2.3.0 & KerasTuner==1.0.2**\n",
        "* If some codes are not working, try install tf & kerastuner with above version."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFfv9JZdpX4A",
        "outputId": "2013d5f4-403b-4d87-c735-40506780cfc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "\n",
        "print(tf.__version__)\n",
        "print(kt.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9mEgqoN5P-z",
        "outputId": "6959ef4e-4de2-47f1-cb26-7b7dc0f605f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJN2hfRfOcym"
      },
      "source": [
        "## -> Jump to section 3 (section 2 is just for additional knowledge)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "id": "StGcl6OvfmYh",
        "outputId": "01cb31d8-17a1-4620-8591-545de982b3f7"
      },
      "source": [
        "from tensorflow.keras import datasets, Sequential, utils\n",
        "from tensorflow.keras.layers import Flatten, Conv2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# 1. Prepare & preprocess the data\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1) / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1) / 255\n",
        "\n",
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "# 2. Build the model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# 3. Fit the model & Visualize the result\n",
        "\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=3, batch_size=200)\n",
        "print('\\nAccuracy: {:.4f}'.format(model.evaluate(x_test, y_test)[1]))\n",
        "\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Test-set Loss\")\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36864)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                737300    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 756,326\n",
            "Trainable params: 756,326\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "300/300 [==============================] - 21s 26ms/step - loss: 0.3325 - accuracy: 0.8962 - val_loss: 0.0776 - val_accuracy: 0.9754\n",
            "Epoch 2/3\n",
            "300/300 [==============================] - 7s 23ms/step - loss: 0.1328 - accuracy: 0.9587 - val_loss: 0.0617 - val_accuracy: 0.9805\n",
            "Epoch 3/3\n",
            "300/300 [==============================] - 7s 22ms/step - loss: 0.0994 - accuracy: 0.9688 - val_loss: 0.0462 - val_accuracy: 0.9855\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0462 - accuracy: 0.9855\n",
            "\n",
            "Accuracy: 0.9855\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc2nMTlrjAUW"
      },
      "source": [
        "<br>\n",
        "\n",
        "## 3. Bayesian HPO with Keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATb8bn-ZayvO"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "import IPython\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "peTtVL0xrFBb",
        "outputId": "337a8a7f-15c1-4ebb-97df-482b80bd143e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8j7Bv3yblHa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "bd1002c1-153d-4c91-f0fd-9c75bad6dc6e"
      },
      "source": [
        "# 1) Prepare & preprocess the data\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data/train.csv')\n",
        "df.drop(['index','FLAG_MOBIL'], axis = 1, inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  gender car reality  child_num  income_total           income_type  \\\n",
              "0      F   N       N          0      202500.0  Commercial associate   \n",
              "1      F   N       Y          1      247500.0  Commercial associate   \n",
              "2      M   Y       Y          0      450000.0               Working   \n",
              "3      F   N       Y          0      202500.0  Commercial associate   \n",
              "4      F   Y       Y          0      157500.0         State servant   \n",
              "\n",
              "                        edu_type     family_type           house_type  \\\n",
              "0               Higher education         Married  Municipal apartment   \n",
              "1  Secondary / secondary special  Civil marriage    House / apartment   \n",
              "2               Higher education         Married    House / apartment   \n",
              "3  Secondary / secondary special         Married    House / apartment   \n",
              "4               Higher education         Married    House / apartment   \n",
              "\n",
              "   DAYS_BIRTH  DAYS_EMPLOYED  work_phone  phone  email   occyp_type  \\\n",
              "0      -13899          -4709           0      0      0          NaN   \n",
              "1      -11380          -1540           0      0      1     Laborers   \n",
              "2      -19087          -4434           0      1      0     Managers   \n",
              "3      -15088          -2092           0      1      0  Sales staff   \n",
              "4      -15037          -2105           0      0      0     Managers   \n",
              "\n",
              "   family_size  begin_month  credit  \n",
              "0          2.0         -6.0     1.0  \n",
              "1          3.0         -5.0     1.0  \n",
              "2          2.0        -22.0     2.0  \n",
              "3          2.0        -37.0     0.0  \n",
              "4          2.0        -26.0     2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c515c8e-9c18-4959-8d01-dcd2499187d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>Municipal apartment</td>\n",
              "      <td>-13899</td>\n",
              "      <td>-4709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-11380</td>\n",
              "      <td>-1540</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19087</td>\n",
              "      <td>-4434</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15088</td>\n",
              "      <td>-2092</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-37.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15037</td>\n",
              "      <td>-2105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-26.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c515c8e-9c18-4959-8d01-dcd2499187d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c515c8e-9c18-4959-8d01-dcd2499187d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c515c8e-9c18-4959-8d01-dcd2499187d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.gender = df.gender.replace({'F' : 0, 'M' : 1})\n",
        "df.car = df.car.replace({'N' : 0, 'Y' : 1})\n",
        "df.reality = df.reality.replace({'N' : 0, 'Y' : 1})\n",
        "df.occyp_type = df.occyp_type.fillna('NaN')\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "7J9kcJuXu1VM",
        "outputId": "b8b698e5-a764-4fc6-9789-2c33cb588394"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   gender  car  reality  child_num  income_total           income_type  \\\n",
              "0       0    0        0          0      202500.0  Commercial associate   \n",
              "1       0    0        1          1      247500.0  Commercial associate   \n",
              "2       1    1        1          0      450000.0               Working   \n",
              "\n",
              "                        edu_type     family_type           house_type  \\\n",
              "0               Higher education         Married  Municipal apartment   \n",
              "1  Secondary / secondary special  Civil marriage    House / apartment   \n",
              "2               Higher education         Married    House / apartment   \n",
              "\n",
              "   DAYS_BIRTH  DAYS_EMPLOYED  work_phone  phone  email occyp_type  \\\n",
              "0      -13899          -4709           0      0      0        NaN   \n",
              "1      -11380          -1540           0      0      1   Laborers   \n",
              "2      -19087          -4434           0      1      0   Managers   \n",
              "\n",
              "   family_size  begin_month  credit  \n",
              "0          2.0         -6.0     1.0  \n",
              "1          3.0         -5.0     1.0  \n",
              "2          2.0        -22.0     2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a57d7aeb-2ce3-464d-bc06-4ea7fc82f23f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>Municipal apartment</td>\n",
              "      <td>-13899</td>\n",
              "      <td>-4709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-11380</td>\n",
              "      <td>-1540</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19087</td>\n",
              "      <td>-4434</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-22.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a57d7aeb-2ce3-464d-bc06-4ea7fc82f23f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a57d7aeb-2ce3-464d-bc06-4ea7fc82f23f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a57d7aeb-2ce3-464d-bc06-4ea7fc82f23f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['age'] = df.DAYS_BIRTH.apply(lambda x : -x // 365)\n",
        "df.DAYS_EMPLOYED = (-1) * df.DAYS_EMPLOYED \n",
        "df.loc[(df.DAYS_EMPLOYED < 0), 'DAYS_EMPLOYED'] = 0\n",
        "df.begin_month = (-1) * df.begin_month"
      ],
      "metadata": {
        "id": "Mph2DnGxu3pd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.credit\n",
        "X = df.drop(['credit', 'DAYS_BIRTH'], axis = 1)"
      ],
      "metadata": {
        "id": "fbDpAuGEu5nP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "T5Ir6Qgfu9yc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = ['child_num', 'income_total', 'DAYS_EMPLOYED', 'family_size', 'begin_month', 'age']\n",
        "numeric_transformer = StandardScaler()\n",
        "\n",
        "categorical_features = ['income_type', 'edu_type', 'family_type', 'house_type','occyp_type']\n",
        "categorical_transformer = OneHotEncoder(categories='auto', handle_unknown = 'ignore')\n",
        "\n",
        "# label_features = ['credit']\n",
        "# label_transformer = LabelEncoder()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "                transformers=[\n",
        "                    ('num', numeric_transformer, numeric_features),\n",
        "                    ('cat', categorical_transformer, categorical_features)\n",
        "                ], remainder='passthrough'\n",
        "                )"
      ],
      "metadata": {
        "id": "RGRtkR-pvBGK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor.fit(X_train)\n",
        "scaled_X_train = preprocessor.transform(X_train)\n",
        "scaled_X_test = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "fkYLKFQmvE27"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, utils\n",
        "from tensorflow.keras import models, layers, activations, initializers, losses, optimizers, metrics\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection, preprocessing"
      ],
      "metadata": {
        "id": "XEDX77-QvK-H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X_train = pd.DataFrame(scaled_X_train)\n",
        "scaled_X_test = pd.DataFrame(scaled_X_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "\n",
        "y_train = utils.to_categorical(y_train)\n",
        "y_test = utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "JBaBqEocvIdl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2M1Op-Hb7uI"
      },
      "source": [
        "# 2) Build the hyper-model\n",
        "# Available HyperParameter search spaces (https://j.mp/2IXPzh7) : Int, Float, Boolean, Choice, Fixed\n",
        "\n",
        "def build_hyper_model(hp):\n",
        "    \n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    # Tune the number of hidden layer (Choose an optimal value between 1~3)\n",
        "    for layer_num in range(hp.Int('num_layers', min_value=1, max_value=3)): \n",
        "        # Tune the number of perceptrons in a dense layer (Choose an optimal value between 32~512) \n",
        "        hp_units = hp.Int('units_' + str(layer_num), min_value=scaled_X_train.shape[1], max_value=512, step=32) # 32:512 & step 32, all parameter names should be unique (we name the inner parameters 'units_' + str(i))\n",
        "        hp_activations = hp.Choice('activation_' + str(layer_num), values=['relu', 'elu']) #choice는 문자열 후보[relu', 'elu']중 하나 고르는거 \n",
        "        model.add(layers.Dense(units = hp_units, activation = hp_activations))\n",
        "\n",
        "    model.add(layers.Dense(3, activation='softmax')) # class 10 : 0~9\n",
        "\n",
        "    # Tune the learning rate for the optimizer (Choose an optimal value from 0.01, 0.001, or 0.0001)\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
        "    \n",
        "    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
        "                loss = keras.losses.categorical_crossentropy, # use sparse c.c when our labels are looks like \"1\" (single integer), not \"[1,0,0]\" (one-hot vector) (@ http://j.mp/2XS0jmv)\n",
        "                metrics = ['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Select tuner and compile it\n",
        "# Available tuners (https://j.mp/39cWz4n) : kt.BayesianOptimization / kt.Hyperband / kt.RandomSearch / kt.Sklearn (https://j.mp/3nSJn8O)\n",
        "\n",
        "tuner = kt.BayesianOptimization(build_hyper_model,\n",
        "                                objective = 'val_loss', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n",
        "                                max_trials = 10, # 서로 다른 Hyper-params 조합으로 시도할 총 Trial 횟수 설정\n",
        "                                directory = 'test_prac_dir', # Path to the working directory\n",
        "                                project_name = 'semi3_hyper_2') # Name to use as directory name for files saved by this Tuner\n",
        "\n",
        "# tuner = kt.Hyperband(build_hyper_model,\n",
        "#                      objective = 'val_accuracy', # Hyper-params tuning을 위한 목적함수 설정 (metric to minimize or maximize)\n",
        "#                      max_epochs = 5, # 최대 epoch 수 설정, epoch 수 자체도 지정한 최대 횟수 내에서 변화시켜가며 테스트를 진행함 (epochs to train one model) \n",
        "#                      directory = 'test_prac_dir', # Path to the working directory\n",
        "#                      project_name = 'MNIST_hyper_1') # Name to use as directory name for files saved by this Tuner\n",
        "\n",
        "tuner.search_space_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uYthW2b6fiP",
        "outputId": "e76e4505-9cf7-4ce5-ba70-4593e292410d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 52, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "activation_0 (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'elu'], 'ordered': False}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Train the model\n",
        "\n",
        "tuner.search(scaled_X_train, y_train, epochs=200, validation_data = (scaled_X_test, y_test)) # epochs == learning epoch for training a single model(epoch for each trial) \n",
        "\n",
        "\n",
        "# # 아래와 같이 별도의 클래스로 콜백을 정의하여 search 함수에서 활용하면 모든 학습 단계 종료 후 학습 중 발생한 출력 결과를 자동으로 지워낼 수 있습니다.\n",
        "# class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "#   def on_train_end(*args, **kwargs):\n",
        "#     IPython.display.clear_output(wait = True)\n",
        "\n",
        "# tuner.search(x_train, y_train, epochs = 7, validation_data = (x_test, y_test), callbacks = [ClearTrainingOutput()]) # epochs == learning epoch for training a single model "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXSCIHWE6j_2",
        "outputId": "6f938e50-7309-4cba-ab81-16e3e9051300"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 11m 22s]\n",
            "val_loss: 0.8202070593833923\n",
            "\n",
            "Best val_loss So Far: 0.8125104904174805\n",
            "Total elapsed time: 01h 42m 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDlJzL14GVXR",
        "outputId": "4474b761-2c39-4fa7-80ef-7e74e911bc0b"
      },
      "source": [
        "# 5) Check the result \n",
        "\n",
        "tuner.results_summary(num_trials=3) # Show \"n\" best trial results"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in test_prac_dir/semi3_hyper_2\n",
            "Showing 3 best trials\n",
            "<keras_tuner.engine.objective.Objective object at 0x7f9d200ab210>\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 500\n",
            "activation_0: relu\n",
            "learning_rate: 0.001\n",
            "units_1: 84\n",
            "activation_1: elu\n",
            "units_2: 52\n",
            "activation_2: relu\n",
            "Score: 0.8125104904174805\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 500\n",
            "activation_0: elu\n",
            "learning_rate: 0.0001\n",
            "units_1: 52\n",
            "activation_1: elu\n",
            "units_2: 52\n",
            "activation_2: relu\n",
            "Score: 0.8160402178764343\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_0: 372\n",
            "activation_0: elu\n",
            "learning_rate: 0.001\n",
            "units_1: 308\n",
            "activation_1: elu\n",
            "Score: 0.8195051550865173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFbk0Bvo36HR",
        "outputId": "dd07b335-de64-495f-ee2c-658ac6dcf2c4"
      },
      "source": [
        "# Check top-3 trials' hyper-params\n",
        "\n",
        "top3_models = tuner.get_best_hyperparameters(num_trials=3)\n",
        "# print(tuner.get_best_hyperparameters(num_trials=3)[0].space) # 특정 Trial의 Search-space 를 확인할 수 있음\n",
        "# print(tuner.get_best_hyperparameters(num_trials=3)[0].values) # 특정 Trial에 적용된 Hyper-params를 확인할 수 있음\n",
        "\n",
        "for idx, model in enumerate(top3_models):\n",
        "    print('Model performance rank :', idx)\n",
        "    print(model.values)\n",
        "    print()\n",
        "\n",
        "\n",
        "# Check the best trial's hyper-params\n",
        "\n",
        "best_hps = top3_models[0]\n",
        "\n",
        "print(\"\"\"\n",
        "The hyperparameter search is complete. \n",
        "* Optimal # of layers : {}\n",
        "* Optimal value of the learning-rate : {}\"\"\".format(best_hps.get('num_layers'), best_hps.get('learning_rate')))\n",
        "\n",
        "for layer_num in range(best_hps.get('num_layers')):\n",
        "    print('Layer {} - # of Perceptrons :'.format(layer_num), best_hps.get('units_' + str(layer_num)))\n",
        "    print('Layer {} - Applied activation function :'.format(layer_num), best_hps.get('activation_' + str(layer_num)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model performance rank : 0\n",
            "{'num_layers': 3, 'units_0': 500, 'activation_0': 'relu', 'learning_rate': 0.001, 'units_1': 84, 'activation_1': 'elu', 'units_2': 52, 'activation_2': 'relu'}\n",
            "\n",
            "Model performance rank : 1\n",
            "{'num_layers': 3, 'units_0': 500, 'activation_0': 'elu', 'learning_rate': 0.0001, 'units_1': 52, 'activation_1': 'elu', 'units_2': 52, 'activation_2': 'relu'}\n",
            "\n",
            "Model performance rank : 2\n",
            "{'num_layers': 2, 'units_0': 372, 'activation_0': 'elu', 'learning_rate': 0.001, 'units_1': 308, 'activation_1': 'elu'}\n",
            "\n",
            "\n",
            "The hyperparameter search is complete. \n",
            "* Optimal # of layers : 3\n",
            "* Optimal value of the learning-rate : 0.001\n",
            "Layer 0 - # of Perceptrons : 500\n",
            "Layer 0 - Applied activation function : relu\n",
            "Layer 1 - # of Perceptrons : 84\n",
            "Layer 1 - Applied activation function : elu\n",
            "Layer 2 - # of Perceptrons : 52\n",
            "Layer 2 - Applied activation function : relu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "oO2QFJn0L7z_",
        "outputId": "dc6cdf53-9567-439f-acdf-37c1a447c62b"
      },
      "source": [
        "# Get the best model from trials\n",
        "\n",
        "models = tuner.get_best_models(num_models=3) # Keras Sequential models\n",
        "top_model = models[0]\n",
        "top_model.summary()\n",
        "print()\n",
        "\n",
        "results = top_model.evaluate(x_test, y_test)\n",
        "print('Cross-entropy :', results[0])\n",
        "print('Accuracy :', results[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3700f04cff66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Keras Sequential models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtop_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2776\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m           'the model on a batch of data.')\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j5xYX3dOHqV"
      },
      "source": [
        "# We can retrain the model with the optimal hyperparameters from the search.\n",
        "best_hps = top3_models[0]\n",
        "\n",
        "# Build the model with the optimal hyperparameters and train it on the data.\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print('Cross-entropy :', results[0])\n",
        "print('Accuracy :', results[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N53W-VP4X_6Y"
      },
      "source": [
        "# We can also find detailed logs, checkpoints, etc, in the folder \"directory/project_name\".\n",
        "\n",
        "# The [test_prac_dir/MNIST_hyper_1] directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. \n",
        "# If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. \n",
        "# To disable this behavior, pass an additional [overwrite = True] argument while instantiating the tuner.\n",
        "\n",
        "for trial in tuner.oracle.get_best_trials(num_trials=3):\n",
        "    print('Trial-score is :', trial.score)\n",
        "    print('Trial-directory(trial_id) is :', trial.trial_id)\n",
        "    print()\n",
        "\n",
        "# tuner.oracle.trials -> get all trial_id "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtqkwnj_ncpy"
      },
      "source": [
        "<br> \n",
        "\n",
        "## (Appendix) Use pre-trained models for computer vision: HyperResNet & HyperXception\n",
        "\n",
        "* pre-compiled with loss='categorical_crossentropy' & metrics=\\['accuracy']\n",
        "* Next model-trainings take too much time, so try it if you are needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc5odBmRnZZx"
      },
      "source": [
        "from kerastuner.applications import HyperResNet, HyperXception\n",
        "from kerastuner.tuners import Hyperband\n",
        "from kerastuner import HyperParameters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "# (img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data() # if you want to use Fashion-MNIST instead of MNIST\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Prepare the data as needed\n",
        "x_train = x_train.reshape((-1, 28, 28, 1))\n",
        "x_test = x_test.reshape((-1, 28, 28, 1))\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7Wwwyo7b7ni"
      },
      "source": [
        "### Pre-trained ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CAnREsBfdhb"
      },
      "source": [
        "hypermodel = HyperResNet(input_shape=(28, 28, 1), classes=10)\n",
        "\n",
        "# Hyperband performs better than random search with low level computing resource. (Hyperband @ https://arxiv.org/abs/1603.06560)\n",
        "tuner = Hyperband(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=40,\n",
        "    directory='test_prac_dir',\n",
        "    project_name='MNIST_Resnet_1')\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTzEeWQOcATX"
      },
      "source": [
        "### Pre-trained Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CYJdQdeh8Xj"
      },
      "source": [
        "hypermodel = HyperXception(input_shape=(28, 28, 1), classes=10)\n",
        "\n",
        "# This will override the `learning_rate` parameter with your own selection of choices\n",
        "hp = HyperParameters()\n",
        "hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "# we can easily restrict the search space to just a few parameters\n",
        "tuner = Hyperband(\n",
        "    hypermodel,\n",
        "    hyperparameters=hp, # ADDED\n",
        "    tune_new_entries=False, # ADDED (`tune_new_entries=False` prevents unlisted parameters from being tuned)\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=40,\n",
        "    directory='test_prac_dir',\n",
        "    project_name='MNIST_Xception_1')\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
        "tuner.results_summary()\n",
        "\n",
        "# What if you want to tune all available parameters in a hypermodel except the learning rate? @ https://j.mp/2J7jzHj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnupwN59cRnt"
      },
      "source": [
        "### Changing the existing optimizer, loss, or metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5HQ0PcYh0bv"
      },
      "source": [
        "hypermodel = HyperXception(input_shape=(28, 28, 1), classes=10)\n",
        "\n",
        "tuner = Hyperband(\n",
        "    hypermodel,\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss='mse',\n",
        "    metrics=[keras.metrics.Precision(name='precision'),\n",
        "             keras.metrics.Recall(name='recall')],\n",
        "    objective='mse',\n",
        "    max_epochs=40,\n",
        "    directory='test_prac_dir',\n",
        "    project_name='MNIST_Xception_1')\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKOsbyaAigO-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWTZp-ieijmk"
      },
      "source": [
        "<br> \n",
        "\n",
        "## (Appendix) Additional materials \n",
        "\n",
        "* [Keras-Tuner official document](https://keras-team.github.io/keras-tuner/)\n",
        "* [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
        "* \n",
        "[**HParams Dashboard**](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) in TensorBoard to interactively tune model hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZqGDaP_jk5k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}